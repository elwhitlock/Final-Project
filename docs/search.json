[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "I will be exploring the Diabetes Health Indicators Dataset. The response variable of interest is Diabetes_binary, which tells us if an individual has no diabetes or not. The variables I would like to explore for this project are:\n\nHighBP Whether or not they have high blood pressure.\nHighChol Whether or not they have high cholesterol.\nBMI\nAge\nGenHlth Self reported health score with 1 being excellent 5 being poor.\nSex\nSmoker Whether or not they smoked at least 100 cigarettes in their life.\nHvyAlcoholConsump Adult men having more than 14 drinks per week and adult women having more than 7 drinks per week.\n\n\n# packages needed\nlibrary(\"tidyverse\")\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tibble' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'stringr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nReading in the data involves mutating variables that are coded as numbers and turnin g them into factors with the appropriate labels. Note I had to reference the codebook for the data to find the levels for a few of these variables.\n\n# read in data\ndb_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\") |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary,\n                          levels = c(0,1),\n                          labels = c(\"No diabetes\", \"Diabetes\")),\n    \n    HighBP = factor(HighBP,\n                    levels = c(0,1),\n                    labels = c(\"No high BP\", \"High BP\")),\n    \n    HighChol = factor(HighChol,\n                      levels = c(0,1),\n                      labels = c(\"No high cholesterol\", \"High cholesterol\")),\n    \n    CholCheck = factor(CholCheck,\n                       levels = c(0,1),\n                       labels = c(\"No cholesterol check\", \"Checked cholesterol\")),\n    \n    Smoker = factor(Smoker,\n                    levels = c(0,1),\n                    labels = c(\"Non-smoker\", \"Smoker\")),\n    \n    Stroke = factor(Stroke,\n                    levels = c(0,1),\n                    labels = c(\"No stroke\", \"Stroke\")),\n    \n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack,\n                                  levels = c(0,1),\n                                  labels = c(\"No CHD/MI\", \"CHD or MI\")),\n    \n    PhysActivity = factor(PhysActivity,\n                          levels = c(0,1),\n                          labels = c(\"No physical activity\", \"Physically active\")),\n    \n    Fruits = factor(Fruits,\n                    levels = c(0,1),\n                    labels = c(\"No fruit consumed\", \"Fruit consumed\")),\n    \n    Veggies = factor(Veggies, \n                     levels = c(0,1),\n                     labels = c(\"No veggies consumed\", \"Veggies consumed\")),\n\n    HvyAlcoholConsump = factor(HvyAlcoholConsump,\n                               levels = c(0,1),\n                               labels = c(\"Not heavy drinker\", \"Heavy drinker\")),\n\n    AnyHealthcare = factor(AnyHealthcare, \n                           levels = c(0,1),\n                           labels = c(\"No healthcare\", \"Has healthcare\")),\n\n    NoDocbcCost = factor(NoDocbcCost, \n                         levels = c(0,1),\n                         labels = c(\"Did not avoid care due to cost\", \"Avoided care due to cost\")),\n\n    DiffWalk = factor(DiffWalk, \n                      levels = c(0,1),\n                      labels = c(\"No difficulty walking\", \"Difficulty walking\")),\n\n    Sex = factor(Sex, \n                 levels = c(0,1),\n                 labels = c(\"Female\", \"Male\")),\n\n    GenHlth = factor(GenHlth, \n                     levels = c(1,2,3,4,5),\n                     labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\"),\n                     ordered = TRUE),\n\n    Age = factor(Age, \n                 levels = 1:13, \n                 labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                            \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\"),\n                 ordered = TRUE),\n\n    Education = factor(Education, \n                       levels = 1:6, \n                       labels = c(\"No school\", \"Grades 1-8\", \"Grades 9-11\",\"High school graduate\",\n                                  \"Some collegel\",\"College graduate\"), \n                       ordered = TRUE),\n\n    Income = factor(Income, \n                    levels = 1:8, \n                    labels = c(\"&lt;10k\", \"&lt;15k\", \"&lt;20k\", \"&lt;25k\",\"&lt;35k\", \"&lt;50k\",\"&lt;75k\",\"75k+\"),\n                    ordered = TRUE)\n\n  )\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# validate our data read in as desired\nglimpse(db_data)\n\nRows: 253,680\nColumns: 22\n$ Diabetes_binary      &lt;fct&gt; No diabetes, No diabetes, No diabetes, No diabete…\n$ HighBP               &lt;fct&gt; High BP, No high BP, High BP, High BP, High BP, H…\n$ HighChol             &lt;fct&gt; High cholesterol, No high cholesterol, High chole…\n$ CholCheck            &lt;fct&gt; Checked cholesterol, No cholesterol check, Checke…\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;fct&gt; Smoker, Smoker, Non-smoker, Non-smoker, Non-smoke…\n$ Stroke               &lt;fct&gt; No stroke, No stroke, No stroke, No stroke, No st…\n$ HeartDiseaseorAttack &lt;fct&gt; No CHD/MI, No CHD/MI, No CHD/MI, No CHD/MI, No CH…\n$ PhysActivity         &lt;fct&gt; No physical activity, Physically active, No physi…\n$ Fruits               &lt;fct&gt; No fruit consumed, No fruit consumed, Fruit consu…\n$ Veggies              &lt;fct&gt; Veggies consumed, No veggies consumed, No veggies…\n$ HvyAlcoholConsump    &lt;fct&gt; Not heavy drinker, Not heavy drinker, Not heavy d…\n$ AnyHealthcare        &lt;fct&gt; Has healthcare, No healthcare, Has healthcare, Ha…\n$ NoDocbcCost          &lt;fct&gt; Did not avoid care due to cost, Avoided care due …\n$ GenHlth              &lt;ord&gt; Poor, Good, Poor, Very good, Very good, Very good…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;fct&gt; Difficulty walking, No difficulty walking, Diffic…\n$ Sex                  &lt;fct&gt; Female, Female, Female, Female, Female, Male, Fem…\n$ Age                  &lt;ord&gt; 60-64, 50-54, 60-64, 70-74, 70-74, 65-69, 60-64, …\n$ Education            &lt;ord&gt; High school graduate, College graduate, High scho…\n$ Income               &lt;ord&gt; &lt;20k, &lt;10k, 75k+, &lt;50k, &lt;25k, 75k+, &lt;75k, &lt;25k, &lt;…\n\n# check for missing values\ncolSums(is.na(db_data))\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThe data looks like it read in appropriately, I checked for missing values so we could account for them in our EDA where needed, fortunately it seems we do not have any.\nWe will start by doing some summary statistics on our only numeric variable, BMI.\n\n# numeric summary BMI\nBMI_sum &lt;- db_data |&gt;\n  summarize(\n   meanBMI = mean(BMI),\n   sdBMI = sd(BMI)\n  )\nprint(BMI_sum)\n\n# A tibble: 1 × 2\n  meanBMI sdBMI\n    &lt;dbl&gt; &lt;dbl&gt;\n1    28.4  6.61\n\n\nWe see the average BMI is 28.38 which is considered ‘overweight’ according to outside resources I found online.\nWhat would happen if we summarize by our response variable, does weight vary with diabetes status?\n\n# numeric summary BMI by Diabetes_binary\nBMI_sum &lt;- db_data |&gt;\n  group_by(Diabetes_binary)|&gt;\n  summarize(\n   meanBMI = mean(BMI),\n   sdBMI = sd(BMI)\n  )\nprint(BMI_sum)\n\n# A tibble: 2 × 3\n  Diabetes_binary meanBMI sdBMI\n  &lt;fct&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 No diabetes        27.8  6.29\n2 Diabetes           31.9  7.36\n\n\nWe see those who have no diabetes are slightly lower than the overall average at 27.81. Those who have diabetes are slightly higher at 31.94. I want to create a histogram looking into the distribution of BMI by diabetes status, I will also facet by sex to see if that impacts our results.\n\n# Histogram BMI broke down by sex and diabetes_binary\nggplot(db_data, aes(x = BMI, fill=Diabetes_binary)) +\n  facet_wrap(~Sex)+\n  geom_histogram() +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"BMI Distribution\", x = \"BMI\", y = \"Count\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nHere we see that the distribution of BMI by diabetes status is roughly the same for both sexes. We also observe that both those with and without diabetes seem to have a right skewed BMI. This may indicate sex is not a useful predictor of diabetes.\nWhat if we broke this down by age group? We can create another histogram looking into the distribution of BMI by diabetes status but facet on age instead.\n\n# Histogram BMI broke down by age and diabetes_binary\nggplot(db_data, aes(x = BMI, fill=Diabetes_binary)) +\n  facet_wrap(~Age)+\n  geom_histogram() +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"BMI Distribution\", x = \"BMI\", y = \"Count\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nWe see younger people tend to not have diabetes, while older individuals do. The distribution of BMI still looks to similar between age groups and diabetes status, at the very least no distributions stick out to us.\nThinking about overall health lets now look at the contingency table for self reported general health scores.\n\n# contingency table GenHlth\nn_health &lt;- table(db_data$GenHlth)\nn_health\n\n\nExcellent Very good      Good      Fair      Poor \n    45299     89084     75646     31570     12081 \n\n\nMost people reported very good, while the least people reported poor.\nHow does this change when we break it up by diabetes status?\n\n# contingency table GenHlth by Diabetes_binary\nn_health_db &lt;- table(db_data$GenHlth,db_data$Diabetes_binary)\nn_health_db\n\n           \n            No diabetes Diabetes\n  Excellent       44159     1140\n  Very good       82703     6381\n  Good            62189    13457\n  Fair            21780     9790\n  Poor             7503     4578\n\n\nThe overall pattern holds for those without diabetes but for those who do have it we see most people report good health, and the least people report excellent health. This indicates to us that those who have diabetes tend to feel worse about their general health.\nPeople who smoke or consume lots of alcohol generally have poorer health, does this also apply to diabetes, lets check the contingency tables.\n\n# contingency table Smoker by Diabetes_binary\nn_smoke_db &lt;- table(db_data$Smoker,db_data$Diabetes_binary)\nn_smoke_db\n\n            \n             No diabetes Diabetes\n  Non-smoker      124228    17029\n  Smoker           94106    18317\n\n# contingency table HvyAlcoholConsump by Diabetes_binary\nn_smoke_db &lt;- table(db_data$HvyAlcoholConsump,db_data$Diabetes_binary)\nn_smoke_db\n\n                   \n                    No diabetes Diabetes\n  Not heavy drinker      204910    34514\n  Heavy drinker           13424      832\n\n\nHere we see that the heavy drinking group is smaller than the not heavy drinking group for both those with diabetes and those without. However, we we see that the smoker group is larger for the diabetes group. Lets try combining the two into a bar plot that displays proportion (to account for the fact the diabetes group has less observations) to see if this reveals any patterns.\n\n# Bar plot w/ diabetes_binary by HvyAlcoholConsump and smoker\nggplot(db_data, aes(x = Diabetes_binary, fill=HvyAlcoholConsump)) +\n  facet_wrap(~Smoker)+\n  geom_bar(position=\"fill\") +\n  scale_fill_manual( name = \"Alcohol Consumption\",\n                     values = c(\"Not heavy drinker\" = \"#8da0cb\",  \n                                \"Heavy drinker\"     = \"#fc8a47\")) +\n  labs(title = \"Proportion of Diabetes\", x = \"Diabetes Status\", y = \"Proportion\")\n\n\n\n\n\n\n\n\nThis communicates to us that people with diabetes do not have a higher proportion of heavy drinkers who smoke than those without diabetes. Maybe these two variables are not useful in predicting diabetes status.\nFrom my knowledge, cholesterol and blood pressure are important indicators of diabetes. For that reason I will analyze them separately in bar plots that use proportion.\n\n#HighBP\n\n# Proportion bar chart\nggplot(db_data, aes(x = HighBP, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"High Blood Pressure by Diabetes\", y = \"Proportion\")\n\n\n\n\n\n\n\n#HighChol\n\n# Proportion bar chart\nggplot(db_data, aes(x = HighChol, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"High Cholesterol by Diabetes\", y = \"Proportion\")\n\n\n\n\n\n\n\n\nThis theory holds, we see a greater proportion of people with diabetes have high blood pressure, and have high cholesterol compared to those with diabetes with no high blood pressure and no high cholesterol respectively.\nLooking at whats needed for the API section of this project I ran the following additional contingency tables to find the most prevalent classes for categorical variables.\n\n# contingency table HighBP\nn_bp &lt;- table(db_data$HighBP)\nn_bp\n\n\nNo high BP    High BP \n    144851     108829 \n\n# contingency table HighChol\nn_chol &lt;- table(db_data$HighChol)\nn_chol\n\n\nNo high cholesterol    High cholesterol \n             146089              107591 \n\n# contingency table Age\nn_age &lt;- table(db_data$Age)\nn_age\n\n\n18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79   80+ \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363 \n\n\n\n\n\nI think HighBP, HighChol, BMI, Age, and GenHlth will be useful in predicting diabetes status while Sex, Smoker, and HvyAlchoholConsump will not. I will thus being using these five predictors in my modeling!\nClick here for the Modeling Page"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "EDA",
    "section": "",
    "text": "I will be exploring the Diabetes Health Indicators Dataset. The response variable of interest is Diabetes_binary, which tells us if an individual has no diabetes or not. The variables I would like to explore for this project are:\n\nHighBP Whether or not they have high blood pressure.\nHighChol Whether or not they have high cholesterol.\nBMI\nAge\nGenHlth Self reported health score with 1 being excellent 5 being poor.\nSex\nSmoker Whether or not they smoked at least 100 cigarettes in their life.\nHvyAlcoholConsump Adult men having more than 14 drinks per week and adult women having more than 7 drinks per week.\n\n\n# packages needed\nlibrary(\"tidyverse\")\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tibble' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'stringr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nReading in the data involves mutating variables that are coded as numbers and turnin g them into factors with the appropriate labels. Note I had to reference the codebook for the data to find the levels for a few of these variables.\n\n# read in data\ndb_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\") |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary,\n                          levels = c(0,1),\n                          labels = c(\"No diabetes\", \"Diabetes\")),\n    \n    HighBP = factor(HighBP,\n                    levels = c(0,1),\n                    labels = c(\"No high BP\", \"High BP\")),\n    \n    HighChol = factor(HighChol,\n                      levels = c(0,1),\n                      labels = c(\"No high cholesterol\", \"High cholesterol\")),\n    \n    CholCheck = factor(CholCheck,\n                       levels = c(0,1),\n                       labels = c(\"No cholesterol check\", \"Checked cholesterol\")),\n    \n    Smoker = factor(Smoker,\n                    levels = c(0,1),\n                    labels = c(\"Non-smoker\", \"Smoker\")),\n    \n    Stroke = factor(Stroke,\n                    levels = c(0,1),\n                    labels = c(\"No stroke\", \"Stroke\")),\n    \n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack,\n                                  levels = c(0,1),\n                                  labels = c(\"No CHD/MI\", \"CHD or MI\")),\n    \n    PhysActivity = factor(PhysActivity,\n                          levels = c(0,1),\n                          labels = c(\"No physical activity\", \"Physically active\")),\n    \n    Fruits = factor(Fruits,\n                    levels = c(0,1),\n                    labels = c(\"No fruit consumed\", \"Fruit consumed\")),\n    \n    Veggies = factor(Veggies, \n                     levels = c(0,1),\n                     labels = c(\"No veggies consumed\", \"Veggies consumed\")),\n\n    HvyAlcoholConsump = factor(HvyAlcoholConsump,\n                               levels = c(0,1),\n                               labels = c(\"Not heavy drinker\", \"Heavy drinker\")),\n\n    AnyHealthcare = factor(AnyHealthcare, \n                           levels = c(0,1),\n                           labels = c(\"No healthcare\", \"Has healthcare\")),\n\n    NoDocbcCost = factor(NoDocbcCost, \n                         levels = c(0,1),\n                         labels = c(\"Did not avoid care due to cost\", \"Avoided care due to cost\")),\n\n    DiffWalk = factor(DiffWalk, \n                      levels = c(0,1),\n                      labels = c(\"No difficulty walking\", \"Difficulty walking\")),\n\n    Sex = factor(Sex, \n                 levels = c(0,1),\n                 labels = c(\"Female\", \"Male\")),\n\n    GenHlth = factor(GenHlth, \n                     levels = c(1,2,3,4,5),\n                     labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\"),\n                     ordered = TRUE),\n\n    Age = factor(Age, \n                 levels = 1:13, \n                 labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                            \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\"),\n                 ordered = TRUE),\n\n    Education = factor(Education, \n                       levels = 1:6, \n                       labels = c(\"No school\", \"Grades 1-8\", \"Grades 9-11\",\"High school graduate\",\n                                  \"Some collegel\",\"College graduate\"), \n                       ordered = TRUE),\n\n    Income = factor(Income, \n                    levels = 1:8, \n                    labels = c(\"&lt;10k\", \"&lt;15k\", \"&lt;20k\", \"&lt;25k\",\"&lt;35k\", \"&lt;50k\",\"&lt;75k\",\"75k+\"),\n                    ordered = TRUE)\n\n  )\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# validate our data read in as desired\nglimpse(db_data)\n\nRows: 253,680\nColumns: 22\n$ Diabetes_binary      &lt;fct&gt; No diabetes, No diabetes, No diabetes, No diabete…\n$ HighBP               &lt;fct&gt; High BP, No high BP, High BP, High BP, High BP, H…\n$ HighChol             &lt;fct&gt; High cholesterol, No high cholesterol, High chole…\n$ CholCheck            &lt;fct&gt; Checked cholesterol, No cholesterol check, Checke…\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;fct&gt; Smoker, Smoker, Non-smoker, Non-smoker, Non-smoke…\n$ Stroke               &lt;fct&gt; No stroke, No stroke, No stroke, No stroke, No st…\n$ HeartDiseaseorAttack &lt;fct&gt; No CHD/MI, No CHD/MI, No CHD/MI, No CHD/MI, No CH…\n$ PhysActivity         &lt;fct&gt; No physical activity, Physically active, No physi…\n$ Fruits               &lt;fct&gt; No fruit consumed, No fruit consumed, Fruit consu…\n$ Veggies              &lt;fct&gt; Veggies consumed, No veggies consumed, No veggies…\n$ HvyAlcoholConsump    &lt;fct&gt; Not heavy drinker, Not heavy drinker, Not heavy d…\n$ AnyHealthcare        &lt;fct&gt; Has healthcare, No healthcare, Has healthcare, Ha…\n$ NoDocbcCost          &lt;fct&gt; Did not avoid care due to cost, Avoided care due …\n$ GenHlth              &lt;ord&gt; Poor, Good, Poor, Very good, Very good, Very good…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;fct&gt; Difficulty walking, No difficulty walking, Diffic…\n$ Sex                  &lt;fct&gt; Female, Female, Female, Female, Female, Male, Fem…\n$ Age                  &lt;ord&gt; 60-64, 50-54, 60-64, 70-74, 70-74, 65-69, 60-64, …\n$ Education            &lt;ord&gt; High school graduate, College graduate, High scho…\n$ Income               &lt;ord&gt; &lt;20k, &lt;10k, 75k+, &lt;50k, &lt;25k, 75k+, &lt;75k, &lt;25k, &lt;…\n\n# check for missing values\ncolSums(is.na(db_data))\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThe data looks like it read in appropriately, I checked for missing values so we could account for them in our EDA where needed, fortunately it seems we do not have any.\nWe will start by doing some summary statistics on our only numeric variable, BMI.\n\n# numeric summary BMI\nBMI_sum &lt;- db_data |&gt;\n  summarize(\n   meanBMI = mean(BMI),\n   sdBMI = sd(BMI)\n  )\nprint(BMI_sum)\n\n# A tibble: 1 × 2\n  meanBMI sdBMI\n    &lt;dbl&gt; &lt;dbl&gt;\n1    28.4  6.61\n\n\nWe see the average BMI is 28.38 which is considered ‘overweight’ according to outside resources I found online.\nWhat would happen if we summarize by our response variable, does weight vary with diabetes status?\n\n# numeric summary BMI by Diabetes_binary\nBMI_sum &lt;- db_data |&gt;\n  group_by(Diabetes_binary)|&gt;\n  summarize(\n   meanBMI = mean(BMI),\n   sdBMI = sd(BMI)\n  )\nprint(BMI_sum)\n\n# A tibble: 2 × 3\n  Diabetes_binary meanBMI sdBMI\n  &lt;fct&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 No diabetes        27.8  6.29\n2 Diabetes           31.9  7.36\n\n\nWe see those who have no diabetes are slightly lower than the overall average at 27.81. Those who have diabetes are slightly higher at 31.94. I want to create a histogram looking into the distribution of BMI by diabetes status, I will also facet by sex to see if that impacts our results.\n\n# Histogram BMI broke down by sex and diabetes_binary\nggplot(db_data, aes(x = BMI, fill=Diabetes_binary)) +\n  facet_wrap(~Sex)+\n  geom_histogram() +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"BMI Distribution\", x = \"BMI\", y = \"Count\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nHere we see that the distribution of BMI by diabetes status is roughly the same for both sexes. We also observe that both those with and without diabetes seem to have a right skewed BMI. This may indicate sex is not a useful predictor of diabetes.\nWhat if we broke this down by age group? We can create another histogram looking into the distribution of BMI by diabetes status but facet on age instead.\n\n# Histogram BMI broke down by age and diabetes_binary\nggplot(db_data, aes(x = BMI, fill=Diabetes_binary)) +\n  facet_wrap(~Age)+\n  geom_histogram() +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"BMI Distribution\", x = \"BMI\", y = \"Count\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nWe see younger people tend to not have diabetes, while older individuals do. The distribution of BMI still looks to similar between age groups and diabetes status, at the very least no distributions stick out to us.\nThinking about overall health lets now look at the contingency table for self reported general health scores.\n\n# contingency table GenHlth\nn_health &lt;- table(db_data$GenHlth)\nn_health\n\n\nExcellent Very good      Good      Fair      Poor \n    45299     89084     75646     31570     12081 \n\n\nMost people reported very good, while the least people reported poor.\nHow does this change when we break it up by diabetes status?\n\n# contingency table GenHlth by Diabetes_binary\nn_health_db &lt;- table(db_data$GenHlth,db_data$Diabetes_binary)\nn_health_db\n\n           \n            No diabetes Diabetes\n  Excellent       44159     1140\n  Very good       82703     6381\n  Good            62189    13457\n  Fair            21780     9790\n  Poor             7503     4578\n\n\nThe overall pattern holds for those without diabetes but for those who do have it we see most people report good health, and the least people report excellent health. This indicates to us that those who have diabetes tend to feel worse about their general health.\nPeople who smoke or consume lots of alcohol generally have poorer health, does this also apply to diabetes, lets check the contingency tables.\n\n# contingency table Smoker by Diabetes_binary\nn_smoke_db &lt;- table(db_data$Smoker,db_data$Diabetes_binary)\nn_smoke_db\n\n            \n             No diabetes Diabetes\n  Non-smoker      124228    17029\n  Smoker           94106    18317\n\n# contingency table HvyAlcoholConsump by Diabetes_binary\nn_smoke_db &lt;- table(db_data$HvyAlcoholConsump,db_data$Diabetes_binary)\nn_smoke_db\n\n                   \n                    No diabetes Diabetes\n  Not heavy drinker      204910    34514\n  Heavy drinker           13424      832\n\n\nHere we see that the heavy drinking group is smaller than the not heavy drinking group for both those with diabetes and those without. However, we we see that the smoker group is larger for the diabetes group. Lets try combining the two into a bar plot that displays proportion (to account for the fact the diabetes group has less observations) to see if this reveals any patterns.\n\n# Bar plot w/ diabetes_binary by HvyAlcoholConsump and smoker\nggplot(db_data, aes(x = Diabetes_binary, fill=HvyAlcoholConsump)) +\n  facet_wrap(~Smoker)+\n  geom_bar(position=\"fill\") +\n  scale_fill_manual( name = \"Alcohol Consumption\",\n                     values = c(\"Not heavy drinker\" = \"#8da0cb\",  \n                                \"Heavy drinker\"     = \"#fc8a47\")) +\n  labs(title = \"Proportion of Diabetes\", x = \"Diabetes Status\", y = \"Proportion\")\n\n\n\n\n\n\n\n\nThis communicates to us that people with diabetes do not have a higher proportion of heavy drinkers who smoke than those without diabetes. Maybe these two variables are not useful in predicting diabetes status.\nFrom my knowledge, cholesterol and blood pressure are important indicators of diabetes. For that reason I will analyze them separately in bar plots that use proportion.\n\n#HighBP\n\n# Proportion bar chart\nggplot(db_data, aes(x = HighBP, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"High Blood Pressure by Diabetes\", y = \"Proportion\")\n\n\n\n\n\n\n\n#HighChol\n\n# Proportion bar chart\nggplot(db_data, aes(x = HighChol, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual( name = \"Diabetes Status\",\n                     values = c(\"No diabetes\" = \"#4ca0cb\",  \n                                \"Diabetes\"     = \"#ee5b47\")) +\n  labs(title = \"High Cholesterol by Diabetes\", y = \"Proportion\")\n\n\n\n\n\n\n\n\nThis theory holds, we see a greater proportion of people with diabetes have high blood pressure, and have high cholesterol compared to those with diabetes with no high blood pressure and no high cholesterol respectively.\nLooking at whats needed for the API section of this project I ran the following additional contingency tables to find the most prevalent classes for categorical variables.\n\n# contingency table HighBP\nn_bp &lt;- table(db_data$HighBP)\nn_bp\n\n\nNo high BP    High BP \n    144851     108829 \n\n# contingency table HighChol\nn_chol &lt;- table(db_data$HighChol)\nn_chol\n\n\nNo high cholesterol    High cholesterol \n             146089              107591 \n\n# contingency table Age\nn_age &lt;- table(db_data$Age)\nn_age\n\n\n18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79   80+ \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363"
  },
  {
    "objectID": "EDA.html#conclusion",
    "href": "EDA.html#conclusion",
    "title": "EDA",
    "section": "",
    "text": "I think HighBP, HighChol, BMI, Age, and GenHlth will be useful in predicting diabetes status while Sex, Smoker, and HvyAlchoholConsump will not. I will thus being using these five predictors in my modeling!\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Recall based on our EDA we found the following predictors useful when diabetes status (Diabetes_binary) is the response of interest:\n\nHighBP Whether or not they have high blood pressure. We saw people with diabetes are more likely to have high BP.\nHighChol Whether or not they have high cholesterol. We saw people with diabetes are more likely to have high cholesterol.\nBMI People with diabetes have a higher BMI on average.\nAge Younger people are less likely than older people to have diabetes.\nGenHlth Self reported health score with 1 being excellent 5 being poor. People with diabetes tend to rank their general health more poorly than people without diabetes.\n\nAs a result they will be the five variables we include in our modeling done below.\n\n# packages needed\nlibrary(\"tidyverse\")\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tibble' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'stringr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(\"tidymodels\")\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ recipes      1.3.1      ✔ yardstick    1.3.2 \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'scales' was built under R version 4.4.3\n\n\nWarning: package 'infer' was built under R version 4.4.3\n\n\nWarning: package 'modeldata' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.3\n\n\nWarning: package 'tailor' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'workflowsets' was built under R version 4.4.3\n\n\nWarning: package 'yardstick' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(\"ranger\")\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\nWe will follow the same process for reading in our data as in the EDA where we use mutate() and factor to get our variables as the correct type. We do not drop variables here.\n\n# read in data\ndb_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\") |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary,\n                          levels = c(0,1),\n                          labels = c(\"No diabetes\", \"Diabetes\")),\n    \n    HighBP = factor(HighBP,\n                    levels = c(0,1),\n                    labels = c(\"No high BP\", \"High BP\")),\n    \n    HighChol = factor(HighChol,\n                      levels = c(0,1),\n                      labels = c(\"No high cholesterol\", \"High cholesterol\")),\n    \n    CholCheck = factor(CholCheck,\n                       levels = c(0,1),\n                       labels = c(\"No cholesterol check\", \"Checked cholesterol\")),\n    \n    Smoker = factor(Smoker,\n                    levels = c(0,1),\n                    labels = c(\"Non-smoker\", \"Smoker\")),\n    \n    Stroke = factor(Stroke,\n                    levels = c(0,1),\n                    labels = c(\"No stroke\", \"Stroke\")),\n    \n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack,\n                                  levels = c(0,1),\n                                  labels = c(\"No CHD/MI\", \"CHD or MI\")),\n    \n    PhysActivity = factor(PhysActivity,\n                          levels = c(0,1),\n                          labels = c(\"No physical activity\", \"Physically active\")),\n    \n    Fruits = factor(Fruits,\n                    levels = c(0,1),\n                    labels = c(\"No fruit consumed\", \"Fruit consumed\")),\n    \n    Veggies = factor(Veggies, \n                     levels = c(0,1),\n                     labels = c(\"No veggies consumed\", \"Veggies consumed\")),\n\n    HvyAlcoholConsump = factor(HvyAlcoholConsump,\n                               levels = c(0,1),\n                               labels = c(\"Not heavy drinker\", \"Heavy drinker\")),\n\n    AnyHealthcare = factor(AnyHealthcare, \n                           levels = c(0,1),\n                           labels = c(\"No healthcare\", \"Has healthcare\")),\n\n    NoDocbcCost = factor(NoDocbcCost, \n                         levels = c(0,1),\n                         labels = c(\"Did not avoid care due to cost\", \"Avoided care due to cost\")),\n\n    DiffWalk = factor(DiffWalk, \n                      levels = c(0,1),\n                      labels = c(\"No difficulty walking\", \"Difficulty walking\")),\n\n    Sex = factor(Sex, \n                 levels = c(0,1),\n                 labels = c(\"Female\", \"Male\")),\n\n    GenHlth = factor(GenHlth, \n                     levels = c(1,2,3,4,5),\n                     labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\"),\n                     ordered = TRUE),\n\n    Age = factor(Age, \n                 levels = 1:13, \n                 labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                            \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\"),\n                 ordered = TRUE),\n\n    Education = factor(Education, \n                       levels = 1:6, \n                       labels = c(\"No school\", \"Grades 1-8\", \"Grades 9-11\",\"High school graduate\",\n                                  \"Some collegel\",\"College graduate\"), \n                       ordered = TRUE),\n\n    Income = factor(Income, \n                    levels = 1:8, \n                    labels = c(\"&lt;10k\", \"&lt;15k\", \"&lt;20k\", \"&lt;25k\",\"&lt;35k\", \"&lt;50k\",\"&lt;75k\",\"75k+\"),\n                    ordered = TRUE)\n\n  )\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNow we need to split the data for modeling. Per Dr. Post’s request we will do a 70/30 split and a five fold CV. Splitting on Diabetes_binary. To ensure reproducibility I set the seed to 67 (my mom was born in 1967).\n\n# seed\nset.seed(67)\n\n# split\ndata_split &lt;- initial_split(db_data, prop = 0.70, strata = Diabetes_binary)\ntrain_data &lt;- training(data_split)\ntest_data  &lt;- testing(data_split)\n\n# CV folds\ndb_cv_folds &lt;- vfold_cv(train_data, 5)\n\n\n\n\nClassification trees are a predictive modeling technique that uses a series of binary splits on predictor variables to classify observations into groups. Splits are decided based on some impurity metric. Note classification trees are regression trees with a categorical response. Both are easy to interpret, since they rely on visuals. However, they are high-variance models, meaning small changes in the data can lead to a very different tree. Because of this I expect our random forest will perform better.\n\n# create recipe\ntree_rec &lt;- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + GenHlth, data = train_data) \ntree_rec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 5\n\n# model and engine, complexity we will tune\ntree_mod &lt;- decision_tree( cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n# workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_mod)\n\n# grid for tuning complexity parameter (5 levels tested) based on our folds using log \n# loss as specified\ntree_grid &lt;- grid_regular(\n  cost_complexity(), \n  levels = 5\n)\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = db_cv_folds,\n            grid = tree_grid,\n            metrics = metric_set(mn_log_loss))\n\n# grab parameter w/ the best (lowest) log loss\nbest_tree &lt;- select_best(tree_fits, metric = \"mn_log_loss\")\n\n# finalize work flow \nfinal_tree_wf&lt;- finalize_workflow(tree_wkf, best_tree)\n\n\n\n\nA random forest is an ensemble learning method that builds many classification trees and combines their results to produce a more stable and accurate model. Each tree is trained on a bootstrap sample (sampling with replacement) of the data like bagging. The difference is that at each split, only a random subset of predictors is considered. This randomness, in the sample and the predictors, ensures the trees are less correlated with one another. It aggregates the results to get final predictions. Because it averages many trees, a random forest has lower variance and than a single tree. The random forest also uses an impurity metric to decide which tree to go with, like the classification tree.\n\n# recipe, note same as before redefining for clarity\nrf_rec &lt;- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + GenHlth, data = train_data)\n\n# model and engine mtry we will tune\n# i used the min_n and trees options to make the code run on my computer better, my lenovo does not have much memory\nrf_mod &lt;- rand_forest(\n  trees = 300,\n  min_n = 5,\n  mtry  = tune()) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"classification\")\n\n# workflow\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(rf_rec) |&gt;\n  add_model(rf_mod)\n\n# grid for tuning mtry parameter range given we have 5 predictor variables\n# with 3 random levels based on our folds using log loss as specified\nrf_grid &lt;- grid_random(\n  mtry(range = c(1, 5)),\n  size = 2\n)\n\nrf_fits &lt;- rf_wkf |&gt;\n  tune_grid(\n    resamples = db_cv_folds,\n    grid      = rf_grid,\n    metrics   = metric_set(mn_log_loss) \n  )\n\n# grab parameter w/ the best (lowest) log loss\nbest_rf &lt;- rf_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\n\n# finalize work flow fit to training data \nrf_final_wf &lt;- finalize_workflow(rf_wkf, best_rf)\n\n# this is included to lessen weight off my computer for rerunning in API\nrf_final_fit &lt;- fit(rf_final_wf, db_data)\nsaveRDS(rf_final_fit, \"rf_final_model.rds\")\n\n\n\n\nFinally lets compare the two models by fitting on the training set and using the test set to see which one we will choose.\n\n# fit best to training and then run on test set for tree\nfinal_tree_test &lt;- last_fit(final_tree_wf, data_split, metrics = metric_set(mn_log_loss)) |&gt;\n  collect_metrics()\n\nfinal_tree_test\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.331 pre0_mod0_post0\n\n# fit best to training and then run on test set for forest\nfinal_rf_test &lt;- last_fit(rf_final_wf, data_split, metrics = metric_set(mn_log_loss)) |&gt;\n  collect_metrics()\n\nfinal_rf_test\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.329 pre0_mod0_post0\n\n\nWe see the mean log loss is slightly lower for the random forest, .329 versus .331, so that will we our final model!"
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "Recall based on our EDA we found the following predictors useful when diabetes status (Diabetes_binary) is the response of interest:\n\nHighBP Whether or not they have high blood pressure. We saw people with diabetes are more likely to have high BP.\nHighChol Whether or not they have high cholesterol. We saw people with diabetes are more likely to have high cholesterol.\nBMI People with diabetes have a higher BMI on average.\nAge Younger people are less likely than older people to have diabetes.\nGenHlth Self reported health score with 1 being excellent 5 being poor. People with diabetes tend to rank their general health more poorly than people without diabetes.\n\nAs a result they will be the five variables we include in our modeling done below.\n\n# packages needed\nlibrary(\"tidyverse\")\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tibble' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'stringr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(\"tidymodels\")\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ recipes      1.3.1      ✔ yardstick    1.3.2 \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'scales' was built under R version 4.4.3\n\n\nWarning: package 'infer' was built under R version 4.4.3\n\n\nWarning: package 'modeldata' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.3\n\n\nWarning: package 'tailor' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'workflowsets' was built under R version 4.4.3\n\n\nWarning: package 'yardstick' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(\"ranger\")\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\nWe will follow the same process for reading in our data as in the EDA where we use mutate() and factor to get our variables as the correct type. We do not drop variables here.\n\n# read in data\ndb_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\") |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary,\n                          levels = c(0,1),\n                          labels = c(\"No diabetes\", \"Diabetes\")),\n    \n    HighBP = factor(HighBP,\n                    levels = c(0,1),\n                    labels = c(\"No high BP\", \"High BP\")),\n    \n    HighChol = factor(HighChol,\n                      levels = c(0,1),\n                      labels = c(\"No high cholesterol\", \"High cholesterol\")),\n    \n    CholCheck = factor(CholCheck,\n                       levels = c(0,1),\n                       labels = c(\"No cholesterol check\", \"Checked cholesterol\")),\n    \n    Smoker = factor(Smoker,\n                    levels = c(0,1),\n                    labels = c(\"Non-smoker\", \"Smoker\")),\n    \n    Stroke = factor(Stroke,\n                    levels = c(0,1),\n                    labels = c(\"No stroke\", \"Stroke\")),\n    \n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack,\n                                  levels = c(0,1),\n                                  labels = c(\"No CHD/MI\", \"CHD or MI\")),\n    \n    PhysActivity = factor(PhysActivity,\n                          levels = c(0,1),\n                          labels = c(\"No physical activity\", \"Physically active\")),\n    \n    Fruits = factor(Fruits,\n                    levels = c(0,1),\n                    labels = c(\"No fruit consumed\", \"Fruit consumed\")),\n    \n    Veggies = factor(Veggies, \n                     levels = c(0,1),\n                     labels = c(\"No veggies consumed\", \"Veggies consumed\")),\n\n    HvyAlcoholConsump = factor(HvyAlcoholConsump,\n                               levels = c(0,1),\n                               labels = c(\"Not heavy drinker\", \"Heavy drinker\")),\n\n    AnyHealthcare = factor(AnyHealthcare, \n                           levels = c(0,1),\n                           labels = c(\"No healthcare\", \"Has healthcare\")),\n\n    NoDocbcCost = factor(NoDocbcCost, \n                         levels = c(0,1),\n                         labels = c(\"Did not avoid care due to cost\", \"Avoided care due to cost\")),\n\n    DiffWalk = factor(DiffWalk, \n                      levels = c(0,1),\n                      labels = c(\"No difficulty walking\", \"Difficulty walking\")),\n\n    Sex = factor(Sex, \n                 levels = c(0,1),\n                 labels = c(\"Female\", \"Male\")),\n\n    GenHlth = factor(GenHlth, \n                     levels = c(1,2,3,4,5),\n                     labels = c(\"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\"),\n                     ordered = TRUE),\n\n    Age = factor(Age, \n                 levels = 1:13, \n                 labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                            \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\"),\n                 ordered = TRUE),\n\n    Education = factor(Education, \n                       levels = 1:6, \n                       labels = c(\"No school\", \"Grades 1-8\", \"Grades 9-11\",\"High school graduate\",\n                                  \"Some collegel\",\"College graduate\"), \n                       ordered = TRUE),\n\n    Income = factor(Income, \n                    levels = 1:8, \n                    labels = c(\"&lt;10k\", \"&lt;15k\", \"&lt;20k\", \"&lt;25k\",\"&lt;35k\", \"&lt;50k\",\"&lt;75k\",\"75k+\"),\n                    ordered = TRUE)\n\n  )\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNow we need to split the data for modeling. Per Dr. Post’s request we will do a 70/30 split and a five fold CV. Splitting on Diabetes_binary. To ensure reproducibility I set the seed to 67 (my mom was born in 1967).\n\n# seed\nset.seed(67)\n\n# split\ndata_split &lt;- initial_split(db_data, prop = 0.70, strata = Diabetes_binary)\ntrain_data &lt;- training(data_split)\ntest_data  &lt;- testing(data_split)\n\n# CV folds\ndb_cv_folds &lt;- vfold_cv(train_data, 5)"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "",
    "text": "Classification trees are a predictive modeling technique that uses a series of binary splits on predictor variables to classify observations into groups. Splits are decided based on some impurity metric. Note classification trees are regression trees with a categorical response. Both are easy to interpret, since they rely on visuals. However, they are high-variance models, meaning small changes in the data can lead to a very different tree. Because of this I expect our random forest will perform better.\n\n# create recipe\ntree_rec &lt;- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + GenHlth, data = train_data) \ntree_rec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 5\n\n# model and engine, complexity we will tune\ntree_mod &lt;- decision_tree( cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n# workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_mod)\n\n# grid for tuning complexity parameter (5 levels tested) based on our folds using log \n# loss as specified\ntree_grid &lt;- grid_regular(\n  cost_complexity(), \n  levels = 5\n)\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = db_cv_folds,\n            grid = tree_grid,\n            metrics = metric_set(mn_log_loss))\n\n# grab parameter w/ the best (lowest) log loss\nbest_tree &lt;- select_best(tree_fits, metric = \"mn_log_loss\")\n\n# finalize work flow \nfinal_tree_wf&lt;- finalize_workflow(tree_wkf, best_tree)"
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Modeling",
    "section": "",
    "text": "A random forest is an ensemble learning method that builds many classification trees and combines their results to produce a more stable and accurate model. Each tree is trained on a bootstrap sample (sampling with replacement) of the data like bagging. The difference is that at each split, only a random subset of predictors is considered. This randomness, in the sample and the predictors, ensures the trees are less correlated with one another. It aggregates the results to get final predictions. Because it averages many trees, a random forest has lower variance and than a single tree. The random forest also uses an impurity metric to decide which tree to go with, like the classification tree.\n\n# recipe, note same as before redefining for clarity\nrf_rec &lt;- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + GenHlth, data = train_data)\n\n# model and engine mtry we will tune\n# i used the min_n and trees options to make the code run on my computer better, my lenovo does not have much memory\nrf_mod &lt;- rand_forest(\n  trees = 300,\n  min_n = 5,\n  mtry  = tune()) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"classification\")\n\n# workflow\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(rf_rec) |&gt;\n  add_model(rf_mod)\n\n# grid for tuning mtry parameter range given we have 5 predictor variables\n# with 3 random levels based on our folds using log loss as specified\nrf_grid &lt;- grid_random(\n  mtry(range = c(1, 5)),\n  size = 2\n)\n\nrf_fits &lt;- rf_wkf |&gt;\n  tune_grid(\n    resamples = db_cv_folds,\n    grid      = rf_grid,\n    metrics   = metric_set(mn_log_loss) \n  )\n\n# grab parameter w/ the best (lowest) log loss\nbest_rf &lt;- rf_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\n\n# finalize work flow fit to training data \nrf_final_wf &lt;- finalize_workflow(rf_wkf, best_rf)\n\n# this is included to lessen weight off my computer for rerunning in API\nrf_final_fit &lt;- fit(rf_final_wf, db_data)\nsaveRDS(rf_final_fit, \"rf_final_model.rds\")"
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Modeling",
    "section": "",
    "text": "Finally lets compare the two models by fitting on the training set and using the test set to see which one we will choose.\n\n# fit best to training and then run on test set for tree\nfinal_tree_test &lt;- last_fit(final_tree_wf, data_split, metrics = metric_set(mn_log_loss)) |&gt;\n  collect_metrics()\n\nfinal_tree_test\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.331 pre0_mod0_post0\n\n# fit best to training and then run on test set for forest\nfinal_rf_test &lt;- last_fit(rf_final_wf, data_split, metrics = metric_set(mn_log_loss)) |&gt;\n  collect_metrics()\n\nfinal_rf_test\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.329 pre0_mod0_post0\n\n\nWe see the mean log loss is slightly lower for the random forest, .329 versus .331, so that will we our final model!"
  }
]