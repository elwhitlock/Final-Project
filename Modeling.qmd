---
title: "Modeling"
format: html
editor: visual
---

# Modeling the Data

## Introduction

Recall based on our EDA we found the following predictors useful when diabetes status (Diabetes_binary) is the response of interest:

-   **HighBP** Whether or not they have high blood pressure. We saw people with diabetes are more likely to have high BP.
-   **HighChol** Whether or not they have high cholesterol. We saw people with diabetes are more likely to have high cholesterol.
-   **BMI** People with diabetes have a higher BMI on average.
-   **Age** Younger people are less likely than older people to have diabetes.
-   **GenHlth** Self reported health score with 1 being excellent 5 being poor. People with diabetes tend to rank their general health more poorly than people without diabetes.

As a result they will be the five variables we include in our modeling done below.

```{r}
# packages needed
library("tidyverse")
library("tidymodels")
library("ranger")
```

We will follow the process for reading in our data as in the EDA where we use mutate() and factor to get our variables as the correct type. We do not drop variables here.

```{r}
# read in data
db_data <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv") |>
  mutate(
    Diabetes_binary = factor(Diabetes_binary,
                          levels = c(0,1),
                          labels = c("No diabetes", "Diabetes")),
    
    HighBP = factor(HighBP,
                    levels = c(0,1),
                    labels = c("No high BP", "High BP")),
    
    HighChol = factor(HighChol,
                      levels = c(0,1),
                      labels = c("No high cholesterol", "High cholesterol")),
    
    CholCheck = factor(CholCheck,
                       levels = c(0,1),
                       labels = c("No cholesterol check", "Checked cholesterol")),
    
    Smoker = factor(Smoker,
                    levels = c(0,1),
                    labels = c("Non-smoker", "Smoker")),
    
    Stroke = factor(Stroke,
                    levels = c(0,1),
                    labels = c("No stroke", "Stroke")),
    
    HeartDiseaseorAttack = factor(HeartDiseaseorAttack,
                                  levels = c(0,1),
                                  labels = c("No CHD/MI", "CHD or MI")),
    
    PhysActivity = factor(PhysActivity,
                          levels = c(0,1),
                          labels = c("No physical activity", "Physically active")),
    
    Fruits = factor(Fruits,
                    levels = c(0,1),
                    labels = c("No fruit consumed", "Fruit consumed")),
    
    Veggies = factor(Veggies, 
                     levels = c(0,1),
                     labels = c("No veggies consumed", "Veggies consumed")),

    HvyAlcoholConsump = factor(HvyAlcoholConsump,
                               levels = c(0,1),
                               labels = c("Not heavy drinker", "Heavy drinker")),

    AnyHealthcare = factor(AnyHealthcare, 
                           levels = c(0,1),
                           labels = c("No healthcare", "Has healthcare")),

    NoDocbcCost = factor(NoDocbcCost, 
                         levels = c(0,1),
                         labels = c("Did not avoid care due to cost", "Avoided care due to cost")),

    DiffWalk = factor(DiffWalk, 
                      levels = c(0,1),
                      labels = c("No difficulty walking", "Difficulty walking")),

    Sex = factor(Sex, 
                 levels = c(0,1),
                 labels = c("Female", "Male")),

    GenHlth = factor(GenHlth, 
                     levels = c(1,2,3,4,5),
                     labels = c("Excellent", "Very good", "Good", "Fair", "Poor"),
                     ordered = TRUE),

    Age = factor(Age, 
                 levels = 1:13, 
                 labels = c("18-24", "25-29", "30-34", "35-39", "40-44", "45-49",
                            "50-54", "55-59", "60-64", "65-69", "70-74", "75-79", "80+"),
                 ordered = TRUE),

    Education = factor(Education, 
                       levels = 1:6, 
                       labels = c("No school", "Grades 1-8", "Grades 9-11","High school graduate",
                                  "Some collegel","College graduate"), 
                       ordered = TRUE),

    Income = factor(Income, 
                    levels = 1:8, 
                    labels = c("<10k", "<15k", "<20k", "<25k","<35k", "<50k","<75k","75k+"),
                    ordered = TRUE)

  )
```

Now we need to split the data for modeling. Per Dr. Post's request we will do a 70/30 split and a five fold CV. Splitting on Diabetes_binary To ensure reproducibility I set the seed to 67 (my mom was born in 1967).

```{r}
# seed
set.seed(67)

# split
data_split <- initial_split(db_data, prop = 0.70, strata = Diabetes_binary)
train_data <- training(data_split)
test_data  <- testing(data_split)

# CV folds
db_cv_folds <- vfold_cv(train_data, 5)

```

## Classification Tree

Classification trees are a predictive modeling technique that 
uses a series of binary splits on predictor variables to classify observations into groups. Splits are decided based on some metric that indicates improvement for example minimizing sum of squared errors. Note classification trees are regression trees with a categorical response. Both are easy to interpret, since they rely on visuals. However, they are high-variance models, meaning small changes in the data can lead to a very different tree.

```{r}
# create recipe
tree_rec <- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + GenHlth, data = train_data) 
tree_rec

# model and engine, complexity we will tune
tree_mod <- decision_tree( cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")

# workflow
tree_wkf <- workflow() |>
  add_recipe(tree_rec) |>
  add_model(tree_mod)

# grid for tuning complexity parameter (5 levels tested) based on our folds using log 
# loss as specified
tree_grid <- grid_regular(
  cost_complexity(), 
  levels = 5
)

tree_fits <- tree_wkf |> 
  tune_grid(resamples = db_cv_folds,
            grid = tree_grid,
            metrics = metric_set(mn_log_loss))

# grab parameter w/ the best (lowest) log loss
best_tree <- select_best(tree_fits, metric = "mn_log_loss")

# finalize work flow 
final_tree_wf<- finalize_workflow(tree_wkf, best_tree)


```

## Random Forest

A random forest is an ensemble learning method that builds many classification 
trees and combines their results to produce a more stable and accurate model. 
Each tree is trained on a bootstrap sample (sampling with replacement) of the data 
like bagging. The difference is that at each split, only a random subset of predictors
is considered. This randomness ensures the trees are less correlated with one another. 
It aggregates the results to get final predictions. Because it averages many trees, a
random forest has lower variance and than a single tree. 

```{r}
# recipe, note same as before redefining for clarity
rf_rec <- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + GenHlth, data = train_data)

# model and engine mtry we will tune
# i used the min_n and trees options to make the code run on my computer better, my lenovo does not have much memory
rf_mod <- rand_forest(
  trees = 300,
  min_n = 5,
  mtry  = tune()) |>
  set_engine("ranger") |>
  set_mode("classification")

# workflow
rf_wkf <- workflow() |>
  add_recipe(rf_rec) |>
  add_model(rf_mod)

# grid for tuning mtry parameter range given we have 5 predictor variables
# with 3 random levels based on our folds using log loss as specified
rf_grid <- grid_random(
  mtry(range = c(1, 5)),
  size = 2
)

rf_fits <- rf_wkf |>
  tune_grid(
    resamples = db_cv_folds,
    grid      = rf_grid,
    metrics   = metric_set(mn_log_loss) 
  )

# grab parameter w/ the best (lowest) log loss
best_rf <- rf_fits |>
  select_best(metric = "mn_log_loss")

# finalize work flow fit to training data 
rf_final_wf <- finalize_workflow(rf_wkf, best_rf)

# this is included to lessen weight off my computer for rerunning in API
rf_final_fit <- fit(rf_final_wf, db_data)
saveRDS(rf_final_fit, "rf_final_model.rds")

```

## Final Model Selection

Finally lets compare the two models using the test set to see which one we will choose.

```{r}
# fit best to training and then run on test set for tree
final_tree_test <- last_fit(final_tree_wf, data_split, metrics = metric_set(mn_log_loss)) |>
  collect_metrics()

final_tree_test

# fit best to training and then run on test set for forest
final_rf_test <- last_fit(rf_final_wf, data_split, metrics = metric_set(mn_log_loss)) |>
  collect_metrics()

final_rf_test
```
We see the mean log loss is slightly lower for the random forest so that will we
our final model!